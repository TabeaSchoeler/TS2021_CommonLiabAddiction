title_name="sTable 7. Summary of eQTL annotation of lead SNPs associated with the common liability and the individual substance use phenotypes"
Info_text=paste0("Note. eQTL = expression quantitative trait loci; SNP = single nucleotide polymorphism. Position = variant position based on GRCh37. Distance = the distance of the eQTL SNP from the corresponding eQTL gene in kilobases (according to GRCh37). eQTL mapping was done for lead SNPs associated with the common liability and the individual substance use phenotypes, defined as LD-independent genome-wide variants. SNPs used for eQTL mapping were selected based on the Qsnp statistic: From the common liability GWA, only SNPs acting via the common liability were selected (Qsnp p-value < 5×10−8); for the individual substance use phenotypes, only SNPs with heterogeneous effects across the individual substance use phenotypes were selected (Qsnp p-value < 5×10−8). eQTL mapping was done in Qtilizer. Mapped to genes were only variants acting as cis-eQTL (variants in a +/- 1 megabase window around the transcription start site of a given gene) and that remained significant (p<0.05) after falsediscovery rate (FDR)/family-wise error rate (FWER) correction as implemented in Qtlizer.")
sheet=eQTLData
table=mergeQTLTable
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
## +++++++ TABLE: Phenoscanner +++++++++++
# Format decimals
postGWA_clumpPhenoDF_suppl=formatNum(vecNum=c("BETA"), vecP=c("P", "P_pheno"), df=postGWA_clumpPhenoDF)
postGWA_clumpPhenoDF_suppl = subset(postGWA_clumpPhenoDF_suppl, select=c(Label, ID_GENE,  P, trait, P_pheno))
colnames(postGWA_clumpPhenoDF_suppl)=c("GWA data","SNP (mapped gene)", "p-value (current GWA)", "Trait (phenoscanner)", "p-value (phenoscanner)")
head(postGWA_clumpPhenoDF_suppl)
# Create new sheet
PhenoScanData="sTable 8"
addWorksheet(wb, PhenoScanData)
# Add datatable
title_name="sTable 8. Summary of PhenoScanner results for lead SNPs"
Info_text=paste0("Note. SNP = single nucleotide polymorphism. Phenotypic associations for lead SNPs associated with each of the GWAS, defined as the top n=",topNGWA, " LD-independent SNPs associated with the common liability and the individual substance use phenotypes. SNPs included in the phenoscanner search were selected based on the Qsnp statistic: From the common liability GWA, only SNPs acting via the common liability were selected (Qsnp p-value < 5×10−8); for the individual substance use phenotypes, only SNPs with heterogeneous effects across the individual substance use phenotypes were selected (Qsnp p-value < 5×10−8). Listed are the ",nTopSNPsPheno, " most significant genotype-phenotype associations from the PhenoScanner database")
sheet=PhenoScanData
table=postGWA_clumpPhenoDF_suppl
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
## +++++++ TABLE: Pathway analysis GProfiler +++++++++++
postGWA_clumpGO_DF=mergeLongFormat(postGWA_clumpGO, recodeName(phenoNamesComb), cleanLabel = TRUE)
postGWA_clumpGO_table=subset(postGWA_clumpGO_DF, select=c(Label, term_name,source, p_value, Database_sig))
postGWA_clumpGO_table$Database_sig=ifelse(duplicated(postGWA_clumpGO_table$Database_sig)==FALSE, as.character(postGWA_clumpGO_table$Database_sig), " ")
# Format decimals
postGWA_clumpGO_table=formatNum(vecP=c("p_value"), df=postGWA_clumpGO_table)
# Change column names
colnames(postGWA_clumpGO_table)=c("GWA data", "Pathway term name", "Pathway database", "FDR-corrected P value",  "significant pathways")
head(postGWA_clumpGO_table)
# Create new sheet
PathwayData="sTable 9"
addWorksheet(wb, PathwayData)
# Add datatable
title_name="sTable 9. Summary of pathway analysis of genetic variants associated with the common liability and the individual substance use phenotypes"
Info_text="Note. Pathway analysis was done in g:Profiler, including genes identified via positional and eQTL mapping of the LD-independent genome-wide genetic variants. "
sheet=PathwayData
table=postGWA_clumpGO_table
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
## +++++++ Figure: Pathway analysis GProfiler +++++++
# Create new sheet
PathwayFig="Figure 4"
addWorksheet(wb, PathwayFig)
# Add datatable
title_name="Figure 4. Pathway analysis of genes associated with the common liability and substance use phenotypes"
PathwayFig_info=""
# Add parameter
Info_text=paste0("Note. Shown are the results of the pathway analysis conducted in g:Profiler. Input genes were ranked based on a score taking into account the GWA-estimated p-value of each variant and its functional consequences (cf. sMethods in Supplement for details).  g:Profiler then performs incremental enrichment analysis with increasingly large numbers of genetic variants, starting from the top of the ranked list. Genetic variants associated with any of the cigarette use phenotypes and variants associated with any of the alcohol use phenotypes were combined in the ranked lists to represent each substance class (i.e. cigarette versus alcohol). Depicted are the n=",nTopPath, " top significant pathways. All p-values are FDR-corrected for multiple testing. ")
sheet=PathwayFig
PlotPathways=paste0(HOME,"/results/figures/postGWA_clumpGO.pdf")
# Run functions
insertImage(wb,  PathwayFig, PlotPathways, startRow = startRow_figures,  startCol = 2, width = plotGOcomb_width, height = plotGOcomb_height, units="cm")
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
## +++++++ TABLE: Summary statistic files used for LD score regression +++++++++++
# +++++++++  Read in included GWAS summary statistics
gwasSumStast=read.xlsx(paste0(HOME,"/analysis/GenSEM_GWAS.xlsx"))
# Add heritability estimates
ldH2=readRDS(paste0(HOME, "/output/rds/ldH2.rds"))
gwasSumStast=merge(gwasSumStast, ldH2, by="label", all.x=T)
nTraitsLDscore=length(gwasSumStast$label)-1 # Number of traits included in Ldscore with common liability
# Format for supplementary table
gwasSumStast=subset(gwasSumStast, select=c(label, N, link, Publication, h2_est, h2_se, interc_est, interc_se))
colnames(gwasSumStast)=c("Summary statistic file", "Sample size", "Link to summary statistics file", "Link to study", "SNP-based heritability (h2 estimate)", "SNP-based heritability (h2 standard error)", "Intercept (estimate)", "Intercept (standard error)")
# Create new sheet
LDscoreRegressionData="sTable 10"
addWorksheet(wb, LDscoreRegressionData)
# Add datatable
title_name=paste0("sTable 10. Summary statistic files for n=", nTraitsLDscore, " traits used for LD score regression. Heritability (h2) and the intercept were estimated using univariate LD score regression")
Info_text=""
sheet=LDscoreRegressionData
table=gwasSumStast
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
## +++++++ TABLE: Results obtained from LD score regression +++++++++++
# Get number of SNPs removed due heterogeneity
commonLiab_nSNPs_filtered=length(subset(sumStatsList[[1]], Q_chisq_pval >= 5e-08)$SNP)
commonLiab_nSNPs=length(sumStatsList[[1]]$SNP)
commonLiab_nSNPs_removed=commonLiab_nSNPs-commonLiab_nSNPs_filtered
commonLiab_nSNPs_removed_perc=round((100/commonLiab_nSNPs)*commonLiab_nSNPs_removed,2)
# Create new sheet
LDscoreRegression="sTable 11"
addWorksheet(wb, LDscoreRegression)
# Add datatable
title_name="sTable 11. Genetic correlations between the common liability and external traits"
Info_text=paste0("Note. 'Common liability input' refers to the data used in LD score regression analysis. 'Common liability (Qsnp filtered)' data included only SNPs that operated through the common liability (based on Qsnp results, excluding n=",commonLiab_nSNPs_removed," (",commonLiab_nSNPs_removed_perc, "%) SNPs that were significantly heterogenous). 'Common liability' included all SNP effects (n=",commonLiab_nSNPs,") obtained in the GWA on the common liability. ")
sheet=LDscoreRegression
table=LdScoreResultsExport
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
# =============== FIGURE: LD score regression plot ====================
## +++++++ EXPORT RESULTS: FIGURE +++++++++++
# Create new sheet
LDscore_plot_sheet="Figure 5"
addWorksheet(wb, LDscore_plot_sheet)
# Add parameters
title_name="Figure 5. Genetic correlations between the common liability and external traits"
Info_text=paste0("Note. Shown are the genetic correlations (rg) between the common liability and each of the included phenotypes. Of the common liability summary statistics, we excluded n=", commonLiab_nSNPs_removed, " (", commonLiab_nSNPs_removed_perc, "%) variants that showed heterogeneous effects across the individual cigarette and alcohol use phenotypes (Qsnp p-value > 5×10−8), to retain only variants that are likely to operate via the common liability. All genetic correlations were estimated using LD score regression. The asterisk indexes significant genetic correlations after correction for multiple testing (false discovery rate corrected p-value < 0.05, corrected for ",nTestLDscoreRegression," tests). Out of the n=", ldsc_filter_number," correlations tested, ", ldsc_filter_significantCor," remained significant after FDR correction. Bars in blue highlight the genetic correlations between the common liability and external traits, bars in grey highlight the genetic correlations between the common liability and the substance use phenotypes used to derive the common liability. The full set of results is reported in sTable X (Supplement). Sensitivity LD score regression analysis using all SNP estimates on the common liability (i.e. without excluding SNPs based on the QSNP statistic) are also included in the Supplement (sTable X).")
sheet=LDscore_plot_sheet
PlotLDScore=paste0(HOME,"/results/figures/PlotLDScore.pdf")
# Run functions
insertImage(wb,  LDscore_plot_sheet, PlotLDScore, startRow = startRow_figures,  startCol = 2, width = ldscPlot_width, height = ldscPlot_height, units="cm")
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
# =============== FIGURE: LD score regression plot ====================
## +++++++ EXPORT RESULTS: FIGURE +++++++++++
# Create new sheet
LDscore_plot_compare_sheet="sFigure 3"
addWorksheet(wb, LDscore_plot_compare_sheet)
# Add parameters
title_name="sFigure 3. Genetic correlations between the common liability and external traits"
Info_text=paste0("Note. Shown are the genetic correlations (rg) between the common liability and each of the included phenotypes. 'Common liability (Qsnp filtered)' data included only SNPs that operated through the common liability (based on Qsnp results, excluding n=",commonLiab_nSNPs_removed," (",commonLiab_nSNPs_removed_perc, "%) SNPs that were significantly heterogenous). 'Common liability' included all SNP effects (n=",commonLiab_nSNPs,") obtained in the GWA on the common liability. ")
sheet=LDscore_plot_compare_sheet
PlotLDScore_compare=paste0(HOME,"/results/figures/PlotLDScore_compare.pdf")
# Run functions
insertImage(wb,  LDscore_plot_compare_sheet, PlotLDScore_compare, startRow = startRow_figures,  startCol = 2, width = ldscPlot_width_compare, height = ldscPlot_height_compare, units="cm")
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
# =============== FIGURE: Mendelian Randomization ====================
## +++++++ EXPORT RESULTS: FIGURE +++++++++++
# Create new sheet
LDscore_plot_sheet="Figure 6"
addWorksheet(wb, LDscore_plot_sheet)
# Add parameters
title_name="Figure 6. Bi-directional Mendelian Randomization analysis assessing causality between the common liability and the substance use phenotypes"
Info_text=paste0("Note. Shown are the standardized beta coefficients obtained from Mendelian Randomization (MR) analysis assessing the bi-directional relations between the common liability and seven substance use phenotypes. Direct causation was estimated as the effects of the common liability on the substance use phenotypes (direct causation), including n=", nInsturmentsComLiab, " genome-wide significant genetic variants (p < 5 × 10-8) operating through the common liability (Qsnp > 5 × 10-8) as instruments. Reverse causation was assessed by estimating the effects of the individual substance use phenotypes on the common liability, including genome-wide significant genetic variants that did not operate through the common liability (Qsnp < 5 × 10-8) as instruments. Not plotted are MR results for models including a single variant only. The full set of MR results can be found in sTable xx.")
sheet=LDscore_plot_sheet
PlotMR=paste0(HOME,"/results/figures/MrPlot.pdf")
# Run functions
insertImage(wb,  LDscore_plot_sheet, v, startRow = startRow_figures,  startCol = 2, width = MrPlot_height, height = MrPlot_height, units="cm")
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
# =============== TABLE: Mendelian Randomization results ====================
# Create new sheet
MR_res="sTable 12"
addWorksheet(wb, MR_res)
# Add datatable
title_name="sTable 12. Results from bi-directional Mendelian Randomization analysis"
Info_text=""
sheet=MR_res
table=MRout_export
# Run functions
addTable(sheet, table)
headerFunc(title_name, sheet)
InfoFunc(Info_text, sheet)
################################################################
# ====================== Export table ==================
################################################################
# Create new styles
s <- createStyle(fgFill = "#FFFFFF")
h_info <- createStyle(halign = "left",
border = "BOTTOM", fontColour = "black", fgFill = "white", fontSize=16, textDecoration = "Bold", numFmt="TEXT", borderColour = "black")
info_info <- createStyle(halign = "left",
border = NULL, fontColour = "black", fgFill = "white", fontSize=14, textDecoration = NULL, numFmt="TEXT", wrapText=TRUE)
# Run loop
for(curr_sheet in names(wb)){
addStyle(wb,sheet = curr_sheet, s, cols=1:40, rows=1:2000, gridExpand = TRUE)
setColWidths(wb, sheet = curr_sheet, cols=1:40, widths = 20)
addStyle(wb,sheet = curr_sheet, h_info, cols=ColStart:20, rows=RowHeader, gridExpand = TRUE)
addStyle(wb,sheet = curr_sheet, info_info, cols=ColStart:5, rows=RowSubheaderStart, gridExpand = TRUE)
mergeCells(wb,sheet = curr_sheet, cols = 2:8, rows = RowSubheaderStart:RowSubheaderEnds)
}
library( openxlsx)
saveWorkbook(wb, paste0(HOME,"/results/tables/GenomicSEM_resultsNovTest.xlsx"), overwrite = TRUE)
# Open File
openXL(wb)
# remove all of the objects that are stored in the global environment
rm(list = ls())
.libPaths("~/Dropbox/progs/R/library")
load.lib=c('pheatmap', 'ggthemes', 'ggpubr', 'Qtlizer', 'devtools', 'GenomicSEM', 'semPlot', 'data.table', 'Matrix',
'sem', 'Matrix', 'stats', 'semTools', 'ggcorrplot', 'grex', 'openxlsx', 'rJava', 'qqman', 'gmodels', 'ggplot2',
'ggcorrplot', 'tidyverse', 'reshape2', 'pdftools', 'plyr', 'magick', 'phenoscanner', 'VennDiagram','ggpubr',
'biomaRt', 'viridis', 'rdrop2', 'lavaan', 'lavaanPlot', 'DiagrammeRsvg', 'DiagrammeR', 'gprofiler2', 'knitr',
'gridExtra', 'CMplot', 'configr', 'purrr', 'TwoSampleMR')
install.lib<-load.lib[!load.lib %in% installed.packages()]
# Install missing packages
for(lib in install.lib) install.packages(lib, dependencies=TRUE, lib = "~/Dropbox/progs/R/library")
# Load all packages
sapply(load.lib,require,character=TRUE)
HOME="/Users/tabea/Dropbox/githubProjects/TabeaSchoeler/TS2020_GenomicSEM"
# Prepare summary statistic file to be in the right format
funcSelectCol=function(df){
df_sub=subset(df, select=c(SNP, P))
return(df_sub)
}
# Functions
transformP=function(df, Pval){
df$P_logp = -log10(df$P)
df$p_corrected=0.05/length(Pval)
df$P_dich=df$P
df$P_dich[df$P<  df$p_corrected[1]] = "sig"
df$P_dich[df$P>=  df$p_corrected[1]] = "ns"
df$P_fdr=p.adjust(Pval, method = "fdr", n = length(Pval))
df$P_fdr_dich=df$P_fdr
df$P_fdr_dich[df$P_fdr<0.05] = "sig"
df$P_fdr_dich[df$P_fdr>=0.05] = "ns"
df$P_fdr_logp <- -log10(df$P_fdr)
df$p_corrected_log= -log10(df$p_corrected)
return(df)
}
# Function to Merge as rbind
mergeLongFormat=function(list, label, cleanLabel){
dataframe = mapply(`[<-`, list, 'Label', value = label, SIMPLIFY = FALSE)
dataframeOut=dplyr::bind_rows(dataframe)
if (cleanLabel==TRUE) {
dataframeOut$Label=ifelse(duplicated(dataframeOut$Label)==FALSE, as.character(dataframeOut$Label), " ")
return(dataframeOut)
} else {
return(dataframeOut)
}
}
# Derive function to relabel
recodeName=function(data){
data=revalue(data, c("commonLiability"="Common liability",
"F1"="Common liability",
"commonLiability_filtered"= "Common liability (Qsnp filtered)",
"CigaretteDependency" = "Cigarette (dependency)",
"AlcoholDependency" = "Alcohol (dependency)",
"AlcoholFrequency" = "Alcohol (frequency)",
"CigaretteFrequency" = "Cigarette (frequency)",
"AlcoholCessation"= "Alcohol (cessation)",
"CigaretteCessation"= "Cigarette (cessation)",
"CigaretteAgeOnset"= "Cigarette (age of onset)",
"original_cigarette"="Cigarette use phenotypes",
"original_alcohol"="Alcohol use phenotypes"))
return(data)
}
# Rename label (add line breaks)
swr = function(string, nwrap) {
paste(strwrap(string, width=nwrap), collapse="\n")
}
swr = Vectorize(swr)
# Check of order makes sense
orderLabels=function(variable){
variableOut <- factor(variable,
levels = c("commonLiability",
"CigaretteFrequency",
"CigaretteDependency",
"CigaretteCessation" ,
"CigaretteAgeOnset",
"AlcoholFrequency",
"AlcoholDependency",
"AlcoholCessation"))
return(variableOut)
}
# Filter SNPs based on Q-statistic
filterQtest=function(df, name){
print(paste0("Iteration: for ",name))
if (name=="commonLiability") {
print("Common factor")
df=subset(df,   Q_chisq_pval >= 5e-8)
} else {
print("Other substance use phenotypes")
df=subset(df,   Q_chisq_pval < 5e-8)
}
return(df)
}
# Select top SNPs according to p-value
topSNPs=function(data, NtopSNPs){
data=data %>% top_n(NtopSNPs, -(as.numeric(P)))
return(data)
}
# Function to format p-values and number with many decimals
formatNum=function(vecP=NULL, vecNum=NULL, decimal=3, df){
if(length(vecP)!=0){
for (i in 1:length(vecP)) {
print(paste0("Format ",vecP[i]))
df[[vecP[i]]]=formatC(df[[vecP[i]]], digits=decimal) # Format p-values
}
}
if(length(vecNum)!=0){
for (i in 1:length(vecNum)) {
print(paste0("Round ",vecNum[i]))
df[[vecNum[i]]]=round( df[[vecNum[i]]], decimal)
}
}
return(df)
}
# Calculate Effective Sample Size for Factor
funcSampleSize=function(data, name, MAFdat){
# Assess how many SNPs have missing data
data_clean= data %>%
drop_na(SE) # Remove rows with missing data
# Print number of SNPs with missing estimates
print(paste0("Compute effective sample size for", " ", name, ". Number of SNPs with missing data: ",
length(data$SNP)-length(data_clean$SNP)))
df_comb=merge(data_clean, MAFdat, by="SNP", all.x=T, suffixes=c("", ".mafDF") )
# Check if alleles are aligned
data_clean$MAF=ifelse(df_comb$A1 == df_comb$A1.mafDF, df_comb$MAF, 1-df_comb$MAF)
head(data_clean)
# Estimate effective sample size
if(  nrow(  data_clean %>% subset(MAF >= 0.10 & MAF <= 0.40))==0){
print("Can not derive sensitivity estimate")
outN = data_clean %>%
mutate(Zscore = as.numeric(BETA) / as.numeric(SE),
nEff = round((mean(((Zscore / BETA )^2) / (2*MAF*(1-MAF)))),0),
nEff_sens = NA,
GWA_Name=name) %>%
filter(row_number()==1) %>%
subset(select=c(GWA_Name, nEff, nEff_sens))
} else {
print("Can derive sensitivity estimate")
outN = data_clean %>%
mutate(Zscore = as.numeric(BETA) / as.numeric(SE),
nEff = round((mean(((Zscore / BETA )^2) / (2*MAF*(1-MAF)))),0),
GWA_Name=name) %>%
subset(MAF >= 0.10 & MAF <= 0.40) %>%  # MAF limit of 10% and 40%
mutate(Zscore = as.numeric(BETA) / as.numeric(SE),
nEff_sens = round((mean(((Zscore / BETA )^2) / (2*MAF*(1-MAF)))),0) ) %>%
filter(row_number()==1) %>%
subset(select=c(GWA_Name, nEff, nEff_sens))
}
return(outN)
}
# +++++++++ Process output  +++++++++
GWASsumStats=readRDS(paste0(HOME,"/output/rds/commonAll_Sumstats.rds"))
postGWA=list()
phenoNames=names(GWASsumStats)
for(i in 1:length(phenoNames)){
print(paste0(" Read in summary statistic file for ", phenoNames[i]))
sumStats=GWASsumStats[[phenoNames[i]]]
print("Clump GWA data")
# Clumping in TwoSampleMR
clump_input=subset(sumStats, P<5e-8)
colnames(clump_input)=revalue(colnames(clump_input), c("P" = "pval.exposure") )
sumStats_clump=clump_data(clump_input, clump_kb=500, clump_r2=0.1, clump_p1 = 5e-8)$SNP
clumpedSNPsMerged=subset(sumStats, SNP %in% sumStats_clump)
clumpedSNPsMerged$SNPs_tot=length(sumStats$Q_chisq_pval)
clumpedSNPsMerged$SNPs_sig_tot=length(clump_input$SNP) # get total number of significant SNPs (before clumping)
clumpedSNPsMerged$SNPs_sig_clumped=length(clumpedSNPsMerged$SNP)
# ==== eQTL Mapping
print("eQTL mapping")
#) Qtlizer to map genes to eQTL
clumpedSNP_eQTL_query= get_qtls(clumpedSNPsMerged$SNP, corr = NA, max_terms = 5, ld_method = "r2",
ref_version = "hg19", return_obj = "dataframe")
if((length(clumpedSNP_eQTL_query$query_type)==0)){
print("no significant eQTLs identified")
namesDF=colnames(get_qtls("rs62325470", corr = NA, max_terms = 5, ld_method = "r2",
ref_version = "hg19", return_obj = "dataframe"))
clumpedSNP_eQTL_query <- data.frame(matrix(ncol = length(namesDF), nrow = 0))
colnames(clumpedSNP_eQTL_query) <- namesDF
}
if((length(clumpedSNP_eQTL_query$query_type)>0)){
# Note: Distance = distnace between index/proxy variant and gene in kilobases
# 1 Mb (megabase) =  threshold for cis-effects
# 1 MB = 1000 KB
clumpedSNP_eQTL_query=subset(clumpedSNP_eQTL_query, distance<=1000) # selecg cis variants and those significant after FDR correction [eQTL mapping will map SNPs to genes which likely affect expression of those genes up to 1 Mb (cis-eQTL).FUMA: only eQTLs with FDR ≤ 0.05 will be used.]
clumpedSNP_eQTL_query=subset(clumpedSNP_eQTL_query, sign_info=="FDR<5%" | sign_info=="FWER<5%" ) # selecg cis variants and those significant after FDR correction [eQTL mapping will map SNPs to genes which likely affect expression of those genes up to 1 Mb (cis-eQTL).FUMA: only eQTLs with FDR ≤ 0.05 will be used.]
}
# Merge clumped with eQTL
clumpedSNP_eQTL= merge(clumpedSNP_eQTL_query, clumpedSNPsMerged, by.x="query_term",by.y="SNP", all.y=TRUE, suffixes = c("", "y"))
print("add gene description")
if( (length(clumpedSNP_eQTL_query$query_type)==0)){ # if no eQTLs, create empty dataframe
clumpedSNP_eQTL_desc=as.data.frame(matrix(ncol=2, nrow=1))
colnames(clumpedSNP_eQTL_desc)=c("description", "input")
} else {
# Add gene description
description =gconvert(query = discard(clumpedSNP_eQTL$gene, is.na) , organism = "hsapiens",
target="ENSG", mthreshold = Inf, filter_na = TRUE)
clumpedSNP_eQTL_desc=subset(description, select = c(input, description))
}
clumpedSNP_eQTL=merge(clumpedSNP_eQTL, clumpedSNP_eQTL_desc, by.x="gene", by.y="input",all.x=TRUE, suffixes = c("", "y"))
clumpedSNP_eQTL$p_eqtl=clumpedSNP_eQTL$p
clumpedSNP_eQTL$p=NULL
# Do not include p-value as this corresponds to specific tissue (results that are removed)
# ===== GProfiler/Phenoscanner: Add description for genes
print("Gene annotation using gprofiler2") # CHECK TUTORIAL: https://cran.r-project.org/web/packages/gprofiler2/vignettes/gprofiler2.html
# Phenoscanner
print("Run phenoscanner")
pheno <- phenoscanner(snpquery=clumpedSNPsMerged$SNP, build=37, catalogue=c("GWAS"))$snps
pheno$hgnc=revalue(pheno$hgnc, c("-" = NA) )
print("Add Ensembl ID and description")
phenoComplete <- data.frame(hgnc=na.omit(pheno$hgnc)) # remove gene rows with missing values
# Add description
geneEnsembl=gconvert(query = phenoComplete$hgnc, organism = "hsapiens",
target="ENSG", mthreshold = Inf,
filter_na = TRUE)[c("target", "name", "description")]  %>% distinct(name, .keep_all = TRUE)
# Merge pheno and gprofiler results
geneEnsemblPheno=merge(pheno, geneEnsembl, by.x = "hgnc", by.y = "name", all.x = T, suffixes = c("", ".y"))
# Add to first dataframe
clumpedSNPs=merge(clumpedSNPsMerged, geneEnsemblPheno, by.x = "SNP", by.y = "snp", all.x = TRUE, suffixes = c("", "y"))
clumpedSNPs$P_logp = -log10(clumpedSNPs$P)
print(paste0("Number of significant SNPs after clumping: ", length(clumpedSNPs$SNP)))
# Combine all datasets
listOut=list(sumStats, clumpedSNPs, clumpedSNP_eQTL)
names(listOut)=c("sumStats", "clumpedSNPs", 'clumpedSNP_eQTL')
# Save loop estimates in list
postGWA[[i]]=listOut
}
names(postGWA)=phenoNames
# Function to select only unique SNPs
processSNPs=function(df){
# Remove SNPs that exist multiple times (eg when linking to different genes)
df$ID_GENE=paste0(df$SNP, " (", df$hgnc, ")")
df_out=subset(df, duplicated(ID_GENE)==FALSE, select = c("SNP","CHR" ,"A1","A2" ,"BETA", "SE", "BP","P_logp", "P", "Q_chisq_pval", "hgnc","target" ,"ID_GENE", "consequence", "pos_hg19", "description","SNPs_tot" ,"SNPs_sig_tot", "SNPs_sig_clumped") )
print(paste0("Number SNPs included following gene annotation: ",   length(df_out$SNP)))
print(paste0("Number of clumped SNPs: ", df$SNPs_sig_clumped[1]))
return(df_out)
}
# Select specific output from FUMA
postGWA_clump=lapply(postGWA, `[[`, "clumpedSNPs") # Select only results from clumping
str(postGWA_clump)
# Select only unique SNP - gene links
postGWA_clump=lapply(postGWA_clump, function(x) processSNPs(x))
postGWA_clump
postGWA_clump[[1]]
# Estimate effective sample size (for common liability)
# Use sumstast files
sumStatsList=lapply(postGWA, `[[`, "sumStats") # Select only results from clumping
names(sumStatsList)=phenoNames
# Estimate in loop
SampleN_GWA=list()
# Download reference file with MAF data: https://utexas.app.box.com/s/vkd36n197m8klbaio3yzoxsee6sxo11v/file/576598996073
MAFdat<-fread(paste0(HOME,"/data/reference.1000G.maf.0.005.txt"))
# Estimate for each GWA
for ( i in 1:length(sumStatsList)) {
SampleN_GWA[[i]]=funcSampleSize(data=sumStatsList[[i]], name=names(sumStatsList)[i], MAFdat=MAFdat)
}
SampleN_GWA_bind=do.call("rbind", SampleN_GWA)
# Read in sumstats info file
GWA_dat=read.xlsx( paste0(HOME,"/analysis/GenSEM_GWAS.xlsx"))
GWA_dat=subset(GWA_dat, directory=="gensem")
# merge dfs
SampleN_GWA_df=merge(SampleN_GWA_bind, GWA_dat, by.x="GWA_Name", by.y="label", all.x = T) %>%
subset(select=c(GWA_Name, nEff, nEff_sens, N))
# FUNCTION: Get number of significant hits (shared vs non-shared)
numberShared=function(df, dataset="individual"){
if((dataset=="combined")){
print("Process combined dataframes")
df=do.call(rbind, df)
df = subset(df, SNP %in% unique(df$SNP))
}
if((dataset=="individual")){
print("Process individual dataframes")
df=df
}
df$minP=min(df$P, na.rm = TRUE)
df$totN_qstat=sum(complete.cases(df$Q_chisq_pval))     # Number of SNPs for which Qsnp estimates are available
df_sub_shared = df %>%
subset(Q_chisq_pval  >= 5e-8)
df_sub_non_shared = df %>%
subset(Q_chisq_pval  < 5e-8)
if( length(df_sub_shared$SNP)==0 ){
df_sub_shared = df %>%
mutate(SNPs_tot = SNPs_tot,
SNPs_sig_tot = SNPs_sig_tot,
SNPs_sig_clumped = SNPs_sig_clumped,
minP = minP,
shared_genes = 0,
shared_snps = 0,
shared_snps_n= 0,
shared_snps_perc = 0,
shared_snps_n_perc=0) %>%
filter(row_number()==1) %>%
subset(select=c(SNPs_tot, SNPs_sig_tot, SNPs_sig_clumped, minP, shared_genes, shared_snps, shared_snps_n_perc))
}
if( length(df_sub_shared$SNP)>0 ){
df_sub_shared = df_sub_shared %>%
mutate(SNPs_tot = SNPs_tot,
SNPs_sig_tot = SNPs_sig_tot,
SNPs_sig_clumped = SNPs_sig_clumped,
minP = minP,
shared_genes = paste(unique(hgnc),   collapse = ", "),
shared_snps = paste(unique(SNP),   collapse = ", "),
shared_snps_n= length(SNP),
shared_snps_perc = round((100/totN_qstat)*shared_snps_n,2),
shared_snps_n_perc=paste0(shared_snps_n, " (", shared_snps_perc, "%)")) %>%
filter(row_number()==1) %>%
subset(select=c(SNPs_tot, SNPs_sig_tot, SNPs_sig_clumped, minP, shared_snps, shared_snps_n_perc, shared_genes))
}
df_sub_non_shared = df_sub_non_shared %>%
mutate(SNPs_tot = SNPs_tot,
SNPs_sig_tot = SNPs_sig_tot,
SNPs_sig_clumped = SNPs_sig_clumped,
minP = minP,
shared_genes = paste(unique(hgnc),   collapse = ", "),
shared_snps = paste(unique(SNP),   collapse = ", "),
shared_snps_n= length(SNP),
shared_snps_perc = round((100/totN_qstat)*shared_snps_n,2),
shared_snps_n_perc=paste0(shared_snps_n, " (", shared_snps_perc, "%)")) %>%
filter(row_number()==1) %>%
subset(select=c(shared_snps, shared_snps_n_perc, shared_genes))
colnames(df_sub_non_shared)=paste0("non_", colnames(df_sub_non_shared))
df_sub=cbind(df_sub_shared, df_sub_non_shared)
return(df_sub)
}
# Get results for clumped data
GWA_shortSum=do.call(rbind, lapply(postGWA_clump, function(x) numberShared(x)))
GWA_shortSum$GWA_Name=phenoNames
GWA_shortSum$GWAS=recodeName(phenoNames)
GWA_shortSum=merge(GWA_shortSum, SampleN_GWA_df, by="GWA_Name", all.x = T)
GWA_shortSum
GWA_shortSum
postGWA_clump
# Get results for clumped data
GWA_shortSum=do.call(rbind, lapply(postGWA_clump, function(x) numberShared(x)))
postGWA_clump
SampleN_GWA_df
postGWA_clump
install.packages('bookdown')
